# CODE DUMP - 2025-10-29 12:00:48
# Project: mini ChatGpt
# Generated by copy_code_to_txt.py

================================================================================

--- FILE: all_code.txt ---
# Path: C:\vs code projects\mini ChatGpt\all_code.txt
# Size: 0 bytes



--------------------------------------------------------------------------------

--- FILE: DECISIONS.md ---
# Path: C:\vs code projects\mini ChatGpt\DECISIONS.md
# Size: 607 bytes

# DECISIONS.md

## DB: PostgreSQL + Prisma
- ACID, relations, cursor pagination
- `prisma migrate deploy` in Docker
- Type-safe queries

## Backend: Node.js + Express + TypeScript
- Shared types with frontend
- Lightweight Docker image
- Full TS stack

## LLM Adapter
- `LLM_PROVIDER=mock|ollama`
- No code changes to switch
- Retry (2x), timeout (12s), cancel

## Pagination
- Cursor-based on `(createdAt DESC, id DESC)`
- Stable, no duplicates

## Resilience
- 500 → retry with backoff
- Hang → 12s timeout
- Cancel → aborts fetch

## Health Checks
- `/healthz`, `/readyz`

--------------------------------------------------------------------------------

--- FILE: docker-compose.yml ---
# Path: C:\vs code projects\mini ChatGpt\docker-compose.yml
# Size: 1733 bytes

services:
  # === DATABASE: PostgreSQL (Persistent) ===
  db:
    image: postgres:16
    container_name: chatgpt-db
    environment:
      POSTGRES_DB: chatgpt
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 5s

  # === MOCK LLM (Provided) ===
  mock-llm:
    build: ./mock-llm
    container_name: mock-llm
    ports:
      - "8080:8080"
    # Remove healthcheck — curl not in node:20-alpine
    # healthcheck:
    #   test: ["CMD", "curl", "-f", "http://localhost:8080/complete"]

  # === BACKEND: Node.js + Express + Prisma ===
  backend:
    build: ./backend
    container_name: chatgpt-backend
    ports:
      - "3001:3001"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/chatgpt?schema=public
      - LLM_PROVIDER=mock
      - MOCK_LLM_BASE_URL=http://mock-llm:8080
    depends_on:
      db:
        condition: service_healthy
      # Remove mock-llm dependency
      # mock-llm:
      #   condition: service_healthy
    command: >
      sh -c "
        echo 'Waiting for DB...' &&
        until nc -z db 5432; do sleep 1; done &&
        echo 'DB ready. Running migrations...' &&
        npx prisma migrate deploy &&
        echo 'Starting backend...' &&
        npm start
      "

  # === FRONTEND: React + MUI + Nginx ===
  frontend:
    build: ./front
    container_name: chatgpt-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend

volumes:
  postgres_data:

--------------------------------------------------------------------------------

--- FILE: backend\package.json ---
# Path: C:\vs code projects\mini ChatGpt\backend\package.json
# Size: 671 bytes

{
  "name": "backend",
  "version": "1.0.0",
  "main": "dist/server.js",
  "scripts": {
    "build": "tsc",
    "start": "node dist/server.js",
    "dev": "ts-node src/server.ts",
    "migrate": "prisma migrate deploy"
  },
  "dependencies": {
    "@prisma/client": "^5.19.0",
    "axios": "^1.7.7",
    "cors": "^2.8.5",
    "express": "^4.19.2",
    "express-async-errors": "^3.1.1",
    "uuid": "^10.0.0"
  },
  "devDependencies": {
    "@types/cors": "^2.8.17",
    "@types/express": "^4.17.21",
    "@types/node": "^20.16.5",
    "@types/uuid": "^10.0.0",
    "prisma": "^5.19.0",
    "ts-node": "^10.9.2",
    "typescript": "^5.6.2"
  }
}

--------------------------------------------------------------------------------

--- FILE: backend\tsconfig.json ---
# Path: C:\vs code projects\mini ChatGpt\backend\tsconfig.json
# Size: 342 bytes

{
  "compilerOptions": {
    "target": "es2020",
    "module": "commonjs",
    "outDir": "dist",
    "rootDir": "src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true
  },
  "include": ["src"],
  "exclude": ["node_modules"]
}

--------------------------------------------------------------------------------

--- FILE: front\package.json ---
# Path: C:\vs code projects\mini ChatGpt\front\package.json
# Size: 1203 bytes

{
  "name": "front",
  "version": "0.1.0",
  "private": true,
  "dependencies": {
    "@emotion/react": "^11.14.0",
    "@emotion/styled": "^11.14.1",
    "@mui/icons-material": "^7.3.4",
    "@mui/material": "^7.3.4",
    "@reduxjs/toolkit": "^2.9.2",
    "@testing-library/dom": "^10.4.1",
    "@testing-library/jest-dom": "^6.9.1",
    "@testing-library/react": "^16.3.0",
    "@testing-library/user-event": "^13.5.0",
    "@types/jest": "^27.5.2",
    "@types/node": "^16.18.126",
    "@types/react": "^19.2.2",
    "@types/react-dom": "^19.2.2",
    "react": "^19.2.0",
    "react-dom": "^19.2.0",
    "react-redux": "^9.2.0",
    "react-scripts": "5.0.1",
    "typescript": "^4.9.5",
    "web-vitals": "^2.1.4"
  },
  "scripts": {
    "start": "react-scripts start",
    "build": "react-scripts build",
    "test": "react-scripts test",
    "eject": "react-scripts eject"
  },
  "eslintConfig": {
    "extends": [
      "react-app",
      "react-app/jest"
    ]
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}


--------------------------------------------------------------------------------

--- FILE: front\README.md ---
# Path: C:\vs code projects\mini ChatGpt\front\README.md
# Size: 2117 bytes

# Getting Started with Create React App

This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).

## Available Scripts

In the project directory, you can run:

### `npm start`

Runs the app in the development mode.\
Open [http://localhost:3000](http://localhost:3000) to view it in the browser.

The page will reload if you make edits.\
You will also see any lint errors in the console.

### `npm test`

Launches the test runner in the interactive watch mode.\
See the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.

### `npm run build`

Builds the app for production to the `build` folder.\
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.\
Your app is ready to be deployed!

See the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.

### `npm run eject`

**Note: this is a one-way operation. Once you `eject`, you can’t go back!**

If you aren’t satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.

Instead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you’re on your own.

You don’t have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn’t feel obligated to use this feature. However we understand that this tool wouldn’t be useful if you couldn’t customize it when you are ready for it.

## Learn More

You can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).

To learn React, check out the [React documentation](https://reactjs.org/).


--------------------------------------------------------------------------------

--- FILE: front\tsconfig.json ---
# Path: C:\vs code projects\mini ChatGpt\front\tsconfig.json
# Size: 682 bytes

{
  "compilerOptions": {
    "target": "es5",
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": true,
    "skipLibCheck": true,
    "esModuleInterop": true,
    "allowSyntheticDefaultImports": true,
    "strict": true,
    "forceConsistentCasingInFileNames": true,
    "noFallthroughCasesInSwitch": true,
    "module": "esnext",
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",
    "baseUrl": "src",
    "paths": {
      "@/*": ["*"]
    }
  },
  "include": [
    "src"
  ],
  "exclude": [
    "node_modules",
    "build"
  ]
}

--------------------------------------------------------------------------------

--- FILE: mock-llm\package.json ---
# Path: C:\vs code projects\mini ChatGpt\mock-llm\package.json
# Size: 201 bytes

{
  "name": "mock-llm",
  "version": "1.0.0",
  "main": "server.js",
  "license": "MIT",
  "type": "commonjs",
  "dependencies": {
    "body-parser": "^1.20.2",
    "express": "^4.19.2"
  }
}

--------------------------------------------------------------------------------

--- FILE: mock-llm\server.js ---
# Path: C:\vs code projects\mini ChatGpt\mock-llm\server.js
# Size: 811 bytes

const express = require("express");
const bodyParser = require("body-parser");
const app = express();
app.use(bodyParser.json());

function randomInt(n) {
  return Math.floor(Math.random() * n);
}

app.post("/complete", async (req, res) => {
  if (Math.random() < 0.10) return; // hang forever
  if (Math.random() < 0.20) return res.status(500).json({ error: "mock-llm error" });

  const content = (req.body && req.body.content) || "";
  console.log("Mock LLM got:", content);

  const reply = "This is a mock response from a pretend LLM.";
  const delayMs = 500 + randomInt(1500);
  await new Promise(r => setTimeout(r, delayMs));

  return res.json({ completion: reply });
});

const port = process.env.PORT || 8080;
app.listen(port, () => console.log("mock-llm listening on", port));

--------------------------------------------------------------------------------

--- FILE: front\public\index.html ---
# Path: C:\vs code projects\mini ChatGpt\front\public\index.html
# Size: 1721 bytes

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="Web site created using create-react-app"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>React App</title>
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"></div>
    <!--
      This HTML file is a template.
      If you open it directly in the browser, you will see an empty page.

      You can add webfonts, meta tags, or analytics to this file.
      The build step will place the bundled scripts into the <body> tag.

      To begin the development, run `npm start` or `yarn start`.
      To create a production bundle, use `npm run build` or `yarn build`.
    -->
  </body>
</html>


--------------------------------------------------------------------------------

--- FILE: front\public\manifest.json ---
# Path: C:\vs code projects\mini ChatGpt\front\public\manifest.json
# Size: 492 bytes

{
  "short_name": "React App",
  "name": "Create React App Sample",
  "icons": [
    {
      "src": "favicon.ico",
      "sizes": "64x64 32x32 24x24 16x16",
      "type": "image/x-icon"
    },
    {
      "src": "logo192.png",
      "type": "image/png",
      "sizes": "192x192"
    },
    {
      "src": "logo512.png",
      "type": "image/png",
      "sizes": "512x512"
    }
  ],
  "start_url": ".",
  "display": "standalone",
  "theme_color": "#000000",
  "background_color": "#ffffff"
}


--------------------------------------------------------------------------------

--- FILE: front\public\robots.txt ---
# Path: C:\vs code projects\mini ChatGpt\front\public\robots.txt
# Size: 67 bytes

# https://www.robotstxt.org/robotstxt.html
User-agent: *
Disallow:


--------------------------------------------------------------------------------

--- FILE: front\src\App.css ---
# Path: C:\vs code projects\mini ChatGpt\front\src\App.css
# Size: 564 bytes

.App {
  text-align: center;
}

.App-logo {
  height: 40vmin;
  pointer-events: none;
}

@media (prefers-reduced-motion: no-preference) {
  .App-logo {
    animation: App-logo-spin infinite 20s linear;
  }
}

.App-header {
  background-color: #282c34;
  min-height: 100vh;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  font-size: calc(10px + 2vmin);
  color: white;
}

.App-link {
  color: #61dafb;
}

@keyframes App-logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}


--------------------------------------------------------------------------------

--- FILE: front\src\App.test.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\App.test.tsx
# Size: 273 bytes

import React from 'react';
import { render, screen } from '@testing-library/react';
import App from './App';

test('renders learn react link', () => {
  render(<App />);
  const linkElement = screen.getByText(/learn react/i);
  expect(linkElement).toBeInTheDocument();
});


--------------------------------------------------------------------------------

--- FILE: front\src\App.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\App.tsx
# Size: 939 bytes

import { Container, CssBaseline, AppBar, Toolbar, Typography, Box } from '@mui/material';
import ConversationList from './components/ConversationList';
import ChatWindow from './components/ChatWindow';
import { ThemeProvider } from '@mui/material/styles';
import theme from './theme';
import { useState } from 'react';

function App() {
  const [selectedId, setSelectedId] = useState<string | null>(null);

  return (
    <ThemeProvider theme={theme}>
      <CssBaseline />
      <AppBar position="static">
        <Toolbar>
          <Typography variant="h6">Mini ChatGPT</Typography>
        </Toolbar>
      </AppBar>

      <Container maxWidth={false} disableGutters sx={{ display: 'flex', height: 'calc(100vh - 64px)' }}>
        <ConversationList onSelect={setSelectedId} />
        <Box flex={1}>
          <ChatWindow conversationId={selectedId} />
        </Box>
      </Container>
    </ThemeProvider>
  );
}

export default App;

--------------------------------------------------------------------------------

--- FILE: front\src\index.css ---
# Path: C:\vs code projects\mini ChatGpt\front\src\index.css
# Size: 366 bytes

body {
  margin: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
    sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

code {
  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
    monospace;
}


--------------------------------------------------------------------------------

--- FILE: front\src\index.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\index.tsx
# Size: 370 bytes

import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import { Provider } from 'react-redux';
import { store } from './store';

const root = ReactDOM.createRoot(
  document.getElementById('root') as HTMLElement
);
root.render(
  <React.StrictMode>
    <Provider store={store}>
      <App />
    </Provider>
  </React.StrictMode>
);

--------------------------------------------------------------------------------

--- FILE: front\src\react-app-env.d.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\react-app-env.d.ts
# Size: 41 bytes

/// <reference types="react-scripts" />


--------------------------------------------------------------------------------

--- FILE: front\src\reportWebVitals.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\reportWebVitals.ts
# Size: 425 bytes

import { ReportHandler } from 'web-vitals';

const reportWebVitals = (onPerfEntry?: ReportHandler) => {
  if (onPerfEntry && onPerfEntry instanceof Function) {
    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {
      getCLS(onPerfEntry);
      getFID(onPerfEntry);
      getFCP(onPerfEntry);
      getLCP(onPerfEntry);
      getTTFB(onPerfEntry);
    });
  }
};

export default reportWebVitals;


--------------------------------------------------------------------------------

--- FILE: front\src\setupTests.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\setupTests.ts
# Size: 241 bytes

// jest-dom adds custom jest matchers for asserting on DOM nodes.
// allows you to do things like:
// expect(element).toHaveTextContent(/react/i)
// learn more: https://github.com/testing-library/jest-dom
import '@testing-library/jest-dom';


--------------------------------------------------------------------------------

--- FILE: front\src\theme.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\theme.ts
# Size: 203 bytes

import { createTheme } from '@mui/material/styles';

export default createTheme({
  palette: {
    mode: 'light',
    primary: {
      main: '#1976d2',  // ← Fixed: 'd' not 'i'
    },
  },
});

--------------------------------------------------------------------------------

--- FILE: front\src\components\ChatWindow.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\components\ChatWindow.tsx
# Size: 3279 bytes

import { Box, CircularProgress, Button, Stack, Typography } from '@mui/material';
import { useGetConversationQuery, api } from '../store/api';
import { useAppDispatch } from '../store/hooks';
import MessageBubble from './MessageBubble';
import MessageInput from './MessageInput';
import { useEffect, useRef, useState } from 'react';
import type { Message } from '../types';

interface Props {
  conversationId: string | null;
}

export default function ChatWindow({ conversationId }: Props) {
  const dispatch = useAppDispatch();
  const [olderMessages, setOlderMessages] = useState<Message[]>([]);
  const [isLoadingOlder, setIsLoadingOlder] = useState(false);

  const {
    data: convo,
    isLoading,
    isFetching,
    error,
  } = useGetConversationQuery(
    { id: conversationId!, limit: 20 },
    { skip: !conversationId, refetchOnMountOrArgChange: true }
  );

  const scrollRef = useRef<HTMLDivElement>(null);

  // Clear older messages when switching conversation
  useEffect(() => {
    setOlderMessages([]);
  }, [conversationId]);

  useEffect(() => {
    scrollRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [convo?.messages, olderMessages]);

  const handleLoadMore = async () => {
    if (!convo?.pageInfo.prevCursor || !conversationId || isLoadingOlder) return;

    setIsLoadingOlder(true);
    try {
      const result = await dispatch(
        api.endpoints.getConversation.initiate({
          id: conversationId,
          cursor: convo.pageInfo.prevCursor,
          limit: 20,
        })
      ).unwrap();

      setOlderMessages((prev) => [...result.messages, ...prev]);
    } catch (err) {
      console.error('Failed to load older messages', err);
    } finally {
      setIsLoadingOlder(false);
    }
  };

  if (!conversationId) {
    return (
      <Box flex={1} display="flex" alignItems="center" justifyContent="center">
        <Typography color="text.secondary">Select or create a conversation</Typography>
      </Box>
    );
  }

  if (isLoading) {
    return (
      <Box flex={1} display="flex" alignItems="center" justifyContent="center">
        <CircularProgress />
      </Box>
    );
  }

  if (error) {
    return (
      <Box flex={1} p={3}>
        <Typography color="error">
          Failed to load chat: {(error as any).data || 'Try again'}
        </Typography>
      </Box>
    );
  }

  const allMessages = [...olderMessages, ...(convo?.messages || [])];

  return (
    <Box display="flex" flexDirection="column" height="100%">
      {/* Load Older Button */}
      {convo?.pageInfo.prevCursor && (
        <Stack alignItems="center" py={1}>
          <Button
            size="small"
            onClick={handleLoadMore}
            disabled={isLoadingOlder || isFetching}
          >
            {isLoadingOlder ? 'Loading...' : 'Load older messages'}
          </Button>
        </Stack>
      )}

      {/* Messages */}
      <Box flex={1} overflow="auto" p={2}>
        {allMessages.map((m) => (
          <MessageBubble key={m.id} msg={m} />
        ))}
        <div ref={scrollRef} />
      </Box>

      {/* Input */}
      <MessageInput conversationId={conversationId} />
    </Box>
  );
}

--------------------------------------------------------------------------------

--- FILE: front\src\components\ConversationList.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\components\ConversationList.tsx
# Size: 5083 bytes

import {
  List,
  ListItem,
  ListItemText,
  IconButton,
  Drawer,
  Box,
  Typography,
  Button,
  useMediaQuery,
  useTheme,
  Snackbar,
  Alert,
  ListItemButton,
} from '@mui/material';
import DeleteIcon from '@mui/icons-material/Delete';
import AddIcon from '@mui/icons-material/Add';
import MenuIcon from '@mui/icons-material/Menu';
import {
  useGetConversationsQuery,
  useCreateConversationMutation,
  useDeleteConversationMutation,
  api,
} from '../store/api';
import { useState, useEffect } from 'react';
import { useAppDispatch } from '../store/hooks';

interface Props {
  onSelect: (id: string) => void;
}

export default function ConversationList({ onSelect }: Props) {
  const theme = useTheme();
  const isMobile = useMediaQuery(theme.breakpoints.down('md'));
  const [mobileOpen, setMobileOpen] = useState(false);
  const [undoId, setUndoId] = useState<string | null>(null);
  const [undoTimer, setUndoTimer] = useState<NodeJS.Timeout | null>(null);

  const dispatch = useAppDispatch();
  const { data: conversations = [], isLoading, error, refetch } = useGetConversationsQuery();
  const [create] = useCreateConversationMutation();
  const [deleteConvo] = useDeleteConversationMutation();

  const handleDelete = (id: string) => {
    // Optimistic update
    dispatch(
      api.util.updateQueryData('getConversations', undefined, (draft) =>
        draft.filter((c) => c.id !== id)
      )
    );

    const timer = setTimeout(() => {
      deleteConvo(id);
      setUndoId(null);
    }, 5000);

    setUndoId(id);
    setUndoTimer(timer);
  };

  const handleUndo = () => {
    if (undoTimer) clearTimeout(undoTimer);
    setUndoId(null);
    refetch();
  };

  useEffect(() => {
    return () => {
      if (undoTimer) clearTimeout(undoTimer);
    };
  }, [undoTimer]);

  return (
    <>
      {/* Desktop Sidebar */}
      {!isMobile && (
        <Box sx={{ width: 300, borderRight: 1, borderColor: 'divider', overflow: 'auto' }}>
          <InnerList />
        </Box>
      )}

      {/* Mobile Drawer */}
      {isMobile && (
        <>
          <IconButton onClick={() => setMobileOpen(true)} sx={{ ml: 1, mt: 1 }}>
            <MenuIcon />
          </IconButton>
          <Drawer open={mobileOpen} onClose={() => setMobileOpen(false)}>
            <Box sx={{ width: 280 }}>
              <InnerList onClose={() => setMobileOpen(false)} />
            </Box>
          </Drawer>
        </>
      )}

      {/* Undo Snackbar */}
      <Snackbar
        open={!!undoId}
        anchorOrigin={{ vertical: 'bottom', horizontal: 'center' }}
        autoHideDuration={null}
      >
        <Alert
          severity="info"
          action={
            <Button color="inherit" size="small" onClick={handleUndo}>
              UNDO
            </Button>
          }
        >
          Conversation deleted
        </Alert>
      </Snackbar>

      {/* Error State */}
      {error && (
        <Box p={2}>
          <Typography color="error">
            Failed to load conversations: {(error as any).data || 'Try again'}
          </Typography>
          <Button onClick={refetch}>Retry</Button>
        </Box>
      )}
    </>
  );

  function InnerList({ onClose }: { onClose?: () => void }) {
    return (
      <>
        <Box p={2} display="flex" justifyContent="space-between">
          <Typography variant="h6">Chats</Typography>
          <Button
            startIcon={<AddIcon />}
            onClick={async () => {
              try {
                const res = await create().unwrap();
                onSelect(res.id);
                onClose?.();
              } catch (err) {
                console.error('Create failed', err);
              }
            }}
          >
            New
          </Button>
        </Box>

        {isLoading ? (
          <Typography p={2}>Loading...</Typography>
        ) : (
          <List>
            {conversations.map((c) => (
              <ListItem key={c.id} disablePadding>
                <ListItemButton
                  onClick={() => {
                    onSelect(c.id);
                    onClose?.();
                  }}
                  sx={{ pl: 2, pr: 1 }}
                >
                  <ListItemText
                    primary={c.title}
                    secondary={
                      c.lastMessageAt
                        ? new Date(c.lastMessageAt).toLocaleString()
                        : 'No messages'
                    }
                  />
                  <IconButton
                    edge="end"
                    onClick={(e) => {
                      e.stopPropagation();
                      handleDelete(c.id);
                    }}
                  >
                    <DeleteIcon />
                  </IconButton>
                </ListItemButton>
              </ListItem>
            ))}
          </List>
        )}
      </>
    );
  }
}

--------------------------------------------------------------------------------

--- FILE: front\src\components\MessageBubble.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\components\MessageBubble.tsx
# Size: 691 bytes

import { Paper, Typography, Box } from '@mui/material';
import { Message } from '../types';

export default function MessageBubble({ msg }: { msg: Message }) {
  const isUser = msg.role === 'user';
  return (
    <Box sx={{ display: 'flex', justifyContent: isUser ? 'flex-end' : 'flex-start', mb: 1.5 }}>
      <Paper
        sx={{
          maxWidth: '75%',
          p: 1.5,
          bgcolor: isUser ? 'primary.main' : 'grey.100',
          color: isUser ? 'white' : 'text.primary',
          borderRadius: 2,
        }}
      >
        <Typography variant="body1" whiteSpace="pre-wrap">
          {msg.content}
        </Typography>
      </Paper>
    </Box>
  );
}

--------------------------------------------------------------------------------

--- FILE: front\src\components\MessageInput.tsx ---
# Path: C:\vs code projects\mini ChatGpt\front\src\components\MessageInput.tsx
# Size: 3152 bytes

import { TextField, IconButton, Box, CircularProgress } from '@mui/material';
import SendIcon from '@mui/icons-material/Send';
import CancelIcon from '@mui/icons-material/Cancel';
import { useSendMessageMutation, api } from '../store/api';
import { useState, useRef } from 'react';
import { useAppDispatch } from '../store/hooks';

interface Props {
  conversationId: string;
}

export default function MessageInput({ conversationId }: Props) {
  const [send, { isLoading, reset }] = useSendMessageMutation();
  const [value, setValue] = useState('');
  const dispatch = useAppDispatch();
  const tempIdRef = useRef<string | null>(null);

  const handleSend = async () => {
    if (!value.trim() || isLoading) return;

    const tempId = `temp-${Date.now()}`;
    tempIdRef.current = tempId;

    // Optimistic UI
    dispatch(
      api.util.updateQueryData(
        'getConversation',
        { id: conversationId },
        (draft) => {
          draft.messages.push({
            id: tempId,
            role: 'user' as const,
            content: value.trim(),
            createdAt: new Date().toISOString(),
          });
        }
      )
    );

    try {
      await send({
        conversationId,
        content: value.trim(),
      }).unwrap();

      setValue('');
      tempIdRef.current = null;
    } catch (err: any) {
      if (err.name === 'AbortError') {
        console.log('Send cancelled');
      }
      // Remove temp message
      dispatch(
        api.util.updateQueryData(
          'getConversation',
          { id: conversationId },
          (draft) => {
            draft.messages = draft.messages.filter((m) => m.id !== tempId);
          }
        )
      );
      tempIdRef.current = null;
    }
  };

  const handleCancel = () => {
    if (!tempIdRef.current) return;

    // Abort request
    reset();

    // Remove optimistic message
    dispatch(
      api.util.updateQueryData(
        'getConversation',
        { id: conversationId },
        (draft) => {
          draft.messages = draft.messages.filter((m) => m.id !== tempIdRef.current);
        }
      )
    );

    tempIdRef.current = null;
  };

  return (
    <Box p={2} borderTop={1} borderColor="divider">
      <TextField
        fullWidth
        multiline
        maxRows={5}
        value={value}
        onChange={(e) => setValue(e.target.value)}
        onKeyDown={(e) => {
          if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleSend();
          }
        }}
        disabled={isLoading}
        placeholder="Type a message..."
        InputProps={{
          endAdornment: isLoading ? (
            <>
              <CircularProgress size={20} sx={{ mr: 1 }} />
              <IconButton onClick={handleCancel}>
                <CancelIcon />
              </IconButton>
            </>
          ) : (
            <IconButton onClick={handleSend} disabled={!value.trim()}>
              <SendIcon />
            </IconButton>
          ),
        }}
      />
    </Box>
  );
}

--------------------------------------------------------------------------------

--- FILE: front\src\store\api.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\store\api.ts
# Size: 3783 bytes

import { createApi, fetchBaseQuery } from '@reduxjs/toolkit/query/react';
import type {
  Conversation,
  ConversationWithMessages,
  SendResponse,
} from '../types';

export const api = createApi({
  baseQuery: fetchBaseQuery({
    baseUrl: '/api',
    timeout: 12000,
  }),
  tagTypes: ['Conversation'],
  endpoints: (builder) => ({
    getConversations: builder.query<Conversation[], void>({
      query: () => '/conversations',
      providesTags: (result) =>
        result
          ? [
              ...result.map(({ id }) => ({ type: 'Conversation' as const, id })),
              { type: 'Conversation', id: 'LIST' },
            ]
          : [{ type: 'Conversation', id: 'LIST' }],
    }),

    createConversation: builder.mutation<Conversation, void>({
      query: () => ({
        url: '/conversations',
        method: 'POST',
      }),
      invalidatesTags: [{ type: 'Conversation', id: 'LIST' }],
    }),

    getConversation: builder.query<
      ConversationWithMessages,
      { id: string; cursor?: string; limit?: number }
    >({
      query: ({ id, cursor, limit = 20 }) => ({
        url: `/conversations/${id}`,
        params: { messagesCursor: cursor, limit },
      }),
      providesTags: (result, error, { id }) => [{ type: 'Conversation', id }],
    }),

    sendMessage: builder.mutation<
      SendResponse,
      { conversationId: string; content: string }
    >({
      query: ({ conversationId, content }) => ({
        url: `/conversations/${conversationId}/messages`,
        method: 'POST',
        body: { content },
      }),
      invalidatesTags: (result, error, { conversationId }) => [
        { type: 'Conversation', id: conversationId },
        { type: 'Conversation', id: 'LIST' },
      ],
      async onQueryStarted(
        { conversationId, content },
        { dispatch, queryFulfilled }
      ) {
        // Create abort controller
        const controller = new AbortController();
        const signal = controller.signal;

        // Optimistic update
        const patchResult = dispatch(
          api.util.updateQueryData(
            'getConversation',
            { id: conversationId },
            (draft) => {
              const tempId = `temp-${Date.now()}`;
              draft.messages.push({
                id: tempId,
                role: 'user',
                content,
                createdAt: new Date().toISOString(),
              });
            }
          )
        );

        try {
          const { data } = await queryFulfilled;
          dispatch(
            api.util.updateQueryData(
              'getConversation',
              { id: conversationId },
              (draft) => {
                draft.messages = draft.messages.filter((m) => !m.id.startsWith('temp-'));
                draft.messages.push(data.message, data.reply);
              }
            )
          );
        } catch (err: any) {
          if (err.name === 'AbortError') {
            console.log('Send cancelled');
          }
          patchResult.undo();
        }

        // Store controller globally so frontend can access it
        (global as any).abortController = controller;
      },
    }),

    deleteConversation: builder.mutation<void, string>({
      query: (id) => ({
        url: `/conversations/${id}`,
        method: 'DELETE',
      }),
      invalidatesTags: (result, error, id) => [
        { type: 'Conversation', id },
        { type: 'Conversation', id: 'LIST' },
      ],
    }),
  }),
});

export const {
  useGetConversationsQuery,
  useCreateConversationMutation,
  useGetConversationQuery,
  useSendMessageMutation,
  useDeleteConversationMutation,
} = api;

--------------------------------------------------------------------------------

--- FILE: front\src\store\hooks.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\store\hooks.ts
# Size: 327 bytes

import { useDispatch, useSelector, TypedUseSelectorHook } from 'react-redux';
import type { RootState, AppDispatch } from './index';

// Typed versions of useDispatch and useSelector
export const useAppDispatch = () => useDispatch<AppDispatch>();
export const useAppSelector: TypedUseSelectorHook<RootState> = useSelector;

--------------------------------------------------------------------------------

--- FILE: front\src\store\index.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\store\index.ts
# Size: 879 bytes

import { configureStore } from '@reduxjs/toolkit';
import { api } from './api';

// -------------------------------------------------
// 1. Create the store (only one declaration!)
export const store = configureStore({
  reducer: {
    [api.reducerPath]: api.reducer,
  },
  middleware: (getDefaultMiddleware) =>
    getDefaultMiddleware({
      serializableCheck: false,
    }).concat(api.middleware),
});

// -------------------------------------------------
// 2. Type exports (required for hooks)
export type RootState = ReturnType<typeof store.getState>;
export type AppDispatch = typeof store.dispatch;

// -------------------------------------------------
// 3. **DO NOT re-export `store` here** – it is already exported above.
//     Remove any line like: `export { store };` or `import store`
// -------------------------------------------------

--------------------------------------------------------------------------------

--- FILE: front\src\types\index.ts ---
# Path: C:\vs code projects\mini ChatGpt\front\src\types\index.ts
# Size: 573 bytes

export type Role = 'user' | 'assistant';

export interface Message {
  id: string;
  role: Role;
  content: string;
  createdAt: string;
}

export interface Conversation {
  id: string;
  title: string;
  createdAt: string;
  lastMessageAt: string | null;
}

export interface PageInfo {
  nextCursor: string | null;
  prevCursor: string | null;
}

export interface ConversationWithMessages {
  id: string;
  title: string;
  messages: Message[];
  pageInfo: PageInfo;
}

export interface SendResponse {
  message: Message;
  reply: Message;
}

--------------------------------------------------------------------------------

--- FILE: backend\src\server.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\server.ts
# Size: 749 bytes

import express from 'express';
import cors from 'cors';
import conversationsRouter from './routes/conversations';
import messagesRouter from './routes/messages';
import { prisma } from './prisma';

const app = express();
app.use(cors());
app.use(express.json());

app.use('/api/conversations', conversationsRouter);
app.use('/api/conversations', messagesRouter);

app.get('/healthz', (req, res) => res.status(200).send('OK'));
app.get('/readyz', async (req, res) => {
  try {
    await prisma.$queryRaw`SELECT 1`;
    res.status(200).send('OK');
  } catch {
    res.status(500).send('DB not ready');
  }
});

const PORT = process.env.PORT || 3001;
app.listen(PORT, () => {
  console.log(`Backend listening on ${PORT}`);
});

--------------------------------------------------------------------------------

--- FILE: backend\src\adapters\factory.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\adapters\factory.ts
# Size: 663 bytes

import { MockAdapter } from './mockAdapter';
import { OllamaAdapter } from './ollamaAdapter';
import { LlmAdapter } from './llmAdapter';

export function createLlmAdapter(): LlmAdapter {
  const provider = process.env.LLM_PROVIDER || 'mock';

  if (provider === 'mock') {
    const url = process.env.MOCK_LLM_BASE_URL || 'http://mock-llm:8080';
    return new MockAdapter(url);
  }

  if (provider === 'ollama') {
    const url = process.env.OLLAMA_BASE_URL || 'http://ollama:11434';
    const model = process.env.OLLAMA_MODEL || 'llama3';
    return new OllamaAdapter(url, model);
  }

  throw new Error(`Unknown LLM_PROVIDER: ${provider}`);
}

--------------------------------------------------------------------------------

--- FILE: backend\src\adapters\llmAdapter.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\adapters\llmAdapter.ts
# Size: 139 bytes

export interface LlmAdapter {
  complete(messages: { role: 'user' | 'assistant'; content: string }[]): Promise<{ completion: string }>;
}

--------------------------------------------------------------------------------

--- FILE: backend\src\adapters\mockAdapter.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\adapters\mockAdapter.ts
# Size: 465 bytes

import axios from 'axios';
import { LlmAdapter } from './llmAdapter';

export class MockAdapter implements LlmAdapter {
  constructor(private baseUrl: string) {}

  async complete(messages: { role: string; content: string }[]) {
    const content = messages.map(m => `${m.role}: ${m.content}`).join('\n');
    const res = await axios.post(`${this.baseUrl}/complete`, { content }, { timeout: 12000 });
    return { completion: res.data.completion };
  }
}

--------------------------------------------------------------------------------

--- FILE: backend\src\adapters\ollamaAdapter.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\adapters\ollamaAdapter.ts
# Size: 495 bytes

import axios from 'axios';
import { LlmAdapter } from './llmAdapter';

export class OllamaAdapter implements LlmAdapter {
  constructor(private baseUrl: string, private model: string) {}

  async complete(messages: { role: 'user' | 'assistant'; content: string }[]) {
    const res = await axios.post(`${this.baseUrl}/api/chat`, {
      model: this.model,
      messages,
      stream: false,
    }, { timeout: 12000 });

    return { completion: res.data.message.content };
  }
}

--------------------------------------------------------------------------------

--- FILE: backend\src\prisma\index.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\prisma\index.ts
# Size: 328 bytes

import { PrismaClient } from '@prisma/client';

const globalForPrisma = global as unknown as { prisma: PrismaClient };

export const prisma =
  globalForPrisma.prisma ||
  new PrismaClient({
    log: ['query', 'info', 'warn', 'error'],
  });

if (process.env.NODE_ENV !== 'production') globalForPrisma.prisma = prisma;

--------------------------------------------------------------------------------

--- FILE: backend\src\routes\conversations.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\routes\conversations.ts
# Size: 994 bytes

import { Router } from 'express';
import { prisma } from '../prisma';
import { v4 as uuidv4 } from 'uuid';

const router = Router();

let convoCounter = 1;

// GET /api/conversations
router.get('/', async (req, res) => {
  const convos = await prisma.conversation.findMany({
    select: {
      id: true,
      title: true,
      createdAt: true,
      lastMessageAt: true,
    },
    orderBy: { createdAt: 'desc' },
  });
  res.json(convos);
});

// POST /api/conversations
router.post('/', async (req, res) => {
  const title = `Conversation #${convoCounter++}`;
  const convo = await prisma.conversation.create({
    data: { title },
  });
  res.status(201).json({
    id: convo.id,
    title: convo.title,
    createdAt: convo.createdAt,
  });
});

// DELETE /api/conversations/:id
router.delete('/:id', async (req, res) => {
  await prisma.conversation.delete({ where: { id: req.params.id } });
  res.status(204).send();
});

export default router;

--------------------------------------------------------------------------------

--- FILE: backend\src\routes\messages.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\routes\messages.ts
# Size: 2997 bytes

import { Router } from 'express';
import { prisma } from '../prisma';
import { createLlmAdapter } from '../adapters/factory';
import { withRetry } from '../utils/retry';

const router = Router();
const llm = createLlmAdapter();

// GET /api/conversations/:id
router.get('/:id', async (req, res) => {
  const { id } = req.params;
  const cursor = req.query.messagesCursor as string | undefined;
  const limit = parseInt(req.query.limit as string) || 20;

  const convo = await prisma.conversation.findUnique({
    where: { id },
    select: { id: true, title: true },
  });

  if (!convo) return res.status(404).json({ error: 'Not found' });

  const messages = await prisma.message.findMany({
    where: { conversationId: id },
    orderBy: [{ createdAt: 'desc' }, { id: 'desc' }],
    take: limit + 1,
    cursor: cursor ? { id: cursor } : undefined,
    skip: cursor ? 1 : 0,
  });

  const hasMore = messages.length > limit;
  const sliced = hasMore ? messages.slice(0, limit) : messages;
  const reversed = sliced.reverse();

  const prevCursor = reversed[0]?.id || null;
  const nextCursor = hasMore ? messages[messages.length - 1].id : null;

  res.json({
    ...convo,
    messages: reversed,
    pageInfo: { prevCursor, nextCursor },
  });
});

// POST /api/conversations/:id/messages
router.post('/:id/messages', async (req, res) => {
  const { content } = req.body;
  const { id } = req.params;

  const userMsg = await prisma.message.create({
    data: { conversationId: id, role: 'user', content },
  });

  await prisma.conversation.update({
    where: { id },
    data: { lastMessageAt: new Date() },
  });

  try {
    // Fetch history
    const dbHistory = await prisma.message.findMany({
      where: { conversationId: id },
      orderBy: { createdAt: 'asc' },
      select: { role: true, content: true }, // Only send role + content
    });

    // Map to LLM format
    const llmHistory = dbHistory.map(m => ({
      role: m.role as 'user' | 'assistant', // Type assertion (DB enforces)
      content: m.content,
    }));

    const completion = await withRetry(() => llm.complete(llmHistory), 2, 500);

    const assistantMsg = await prisma.message.create({
      data: { conversationId: id, role: 'assistant', content: completion.completion },
    });

    res.json({
      message: {
        id: userMsg.id,
        role: 'user',
        content: userMsg.content,
        createdAt: userMsg.createdAt,
      },
      reply: {
        id: assistantMsg.id,
        role: 'assistant',
        content: assistantMsg.content,
        createdAt: assistantMsg.createdAt,
      },
    });
  } catch (err: any) {
    if (err.name === 'AbortError') {
      await prisma.message.delete({ where: { id: userMsg.id } });
      return res.status(499).json({ error: 'Cancelled' });
    }
    res.status(500).json({ error: 'LLM failed', retryAfterMs: 1000 });
  }
});

export default router;

--------------------------------------------------------------------------------

--- FILE: backend\src\utils\retry.ts ---
# Path: C:\vs code projects\mini ChatGpt\backend\src\utils\retry.ts
# Size: 378 bytes

export async function withRetry<T>(
  fn: () => Promise<T>,
  retries: number,
  delayMs: number
): Promise<T> {
  let lastError;
  for (let i = 0; i <= retries; i++) {
    try {
      return await fn();
    } catch (err: any) {
      lastError = err;
      if (i < retries) await new Promise(r => setTimeout(r, delayMs * (i + 1)));
    }
  }
  throw lastError;
}

--------------------------------------------------------------------------------


# TOTAL FILES COPIED: 39
# Finished at: 2025-10-29 12:00:52
